{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"framingham.csv\"):\n",
    "  os.remove(\"framingham.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://mlopssa.blob.core.windows.net/chd-dataset/framingham.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a boolean array of smokers\n",
    "smoke = (df['currentSmoker']==1)\n",
    "# applying mean to NaNs in cigsPerDay but using a set of smokers only\n",
    "df.loc[smoke,'cigsPerDay'] = df.loc[smoke,'cigsPerDay'].fillna(df.loc[smoke,'cigsPerDay'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling out missing values\n",
    "df['BPMeds'].fillna(0, inplace = True)\n",
    "df['glucose'].fillna(df.glucose.mean(), inplace = True)\n",
    "df['totChol'].fillna(df.totChol.mean(), inplace = True)\n",
    "df['education'].fillna(1, inplace = True)\n",
    "df['BMI'].fillna(df.BMI.mean(), inplace = True)\n",
    "df['heartRate'].fillna(df.heartRate.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:,:-1]\n",
    "result = df.iloc[:,-1] # the last column is what we are about to forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.2, random_state = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.12\n",
    "sfm = SelectFromModel(clf, threshold=0.12)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = list(features.columns.values) # creating a list with features' names\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with only imporant features. Can check X_important_train.shape[1]\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The metrics are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_y_4 = clf_important.predict(X_important_test)\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Classification Report\")\n",
    "print(\"============================\")\n",
    "print(classification_report(y_test, predictions_y_4))\n",
    "print(\"\")\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"============================\")\n",
    "print(confusion_matrix(y_test, predictions_y_4))\n",
    "print(\"\")\n",
    "\n",
    "# Under ROC curve\n",
    "print(\"============================\")\n",
    "print(\"ROC\")\n",
    "print(\"============================\")\n",
    "prob_y_4 = clf_important.predict_proba(X_important_test)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print(roc_auc_score(y_test, prob_y_4))\n",
    "print(\"\")\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Accuracy score\")\n",
    "print(\"============================\")\n",
    "accuracy_score(y_test, predictions_y_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./outputs/model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path on disk\n",
    "filename = './outputs/model/chd-rf-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "pickle.dump(clf_important, open(filename, 'wb'))\n",
    "print(\"model saved in ././outputs/model/ folder\")\n",
    "print(\"Saving model files completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Test... Actual: TenYearCHD=1\n",
    "\n",
    "age = 61\n",
    "prevalentHyp = 1\n",
    "sysBP = 150\n",
    "glucose = 103\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "print(loaded_model.predict([[age, prevalentHyp, sysBP, glucose]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Test... Actual: TenYearCHD=0\n",
    "\n",
    "age = 43\n",
    "prevalentHyp = 1\n",
    "sysBP = 180\n",
    "glucose = 99\n",
    " \n",
    "print(loaded_model.predict([[age, prevalentHyp, sysBP, glucose]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Test... Actual: TenYearCHD=1\n",
    "\n",
    "age = 63\n",
    "prevalentHyp = 0\n",
    "sysBP = 138\n",
    "glucose = 85\n",
    " \n",
    "print(loaded_model.predict([[age, prevalentHyp, sysBP, glucose]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Test... Actual: TenYearCHD=0\n",
    "age = 52\n",
    "prevalentHyp = 1\n",
    "sysBP = 141\n",
    "glucose = 75\n",
    " \n",
    "print(loaded_model.predict([[age, prevalentHyp, sysBP, glucose]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = loaded_model.predict([[61, 1, 150, 103],[43, 1, 180, 99],[63,0,138,85]])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "to_be_scored_json = {\"data\":[[61, 1, 150, 103],[43, 1, 180, 99],[63,0,138,85]]}\n",
    "input_data_json = json.dumps(to_be_scored_json)\n",
    "\n",
    "to_be_scored_list = json.loads(input_data_json)[\"data\"]\n",
    "to_be_scored_list=np.array(to_be_scored_list)\n",
    "print(loaded_model.predict(to_be_scored_list).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
